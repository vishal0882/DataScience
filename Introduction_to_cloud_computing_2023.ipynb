{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal0882/DataScience/blob/main/Introduction_to_cloud_computing_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_ThSd3pH_D"
      },
      "source": [
        "<center><img src=\"https://gitlab.com/accredian/insaid-data/-/raw/main/Logo-Accredian/Case-Study-Cropped.png\" width= 30% /></center>\n",
        "\n",
        "# <center>**Explore Dataset using Bigquery**</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4-A2W21pVWI"
      },
      "source": [
        "----\n",
        "# **Table of Contents:**\n",
        "---\n",
        "\n",
        "**1.** [**Introduction**](#section1)<br>\n",
        "**2.** [**Introduction to Bigquery**](#section2)<br>\n",
        "**3.** [**Explore Bigquery**](#section3)<br>\n",
        "   - **3.1** [**Create a New Project**](#section3.1)<br>\n",
        "   - **3.2** [**Exporting Datasets**](#section3.2)<br>\n",
        "   - **3.3** [**Understanding the Data**](#section3.3)<br>\n",
        "   - **3.4** [**Querying the data**](#section3.4)<br>\n",
        "   - **3.5** [**Data Exploration**](#section3.5)<br>\n",
        "   \n",
        "**4.** [**Conclusion**](#section4)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06C9WC6UkINA"
      },
      "source": [
        "----\n",
        "<a id=section1></a>\n",
        "# **1. Introduction**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The initial step in any **data science workflow** is to acquire and prepare the data to be analyzed.\n",
        "\n",
        "- Typically, data is being **integrated from various** resources and has different formats.\n",
        "\n",
        "- The data preparation follows the data **acquisition** step, which is an **iterative and agile process** for exploring, combining, cleaning and **transforming raw data** into curated datasets for **data integration**, data science, data discovery and **analytics/business intelligence** (BI) use cases.\n",
        "\n",
        "- Notably, even though the **preparation phase** is an intermediate phase aimed to prepare data for **analysis**, this phase is reported to be the most **expensive** with respect to **resources** and time."
      ],
      "metadata": {
        "id": "j0JXFvgA87tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name = Section11></a>\n",
        "### **1.1 Data Extraction**"
      ],
      "metadata": {
        "id": "tbeLmcySXv94"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeS_TY7P9cUN"
      },
      "source": [
        "- Data extraction is the process of **collecting** and **retrieving** data a from a **variety of sources** for further data **processing**, **analysis** and to store elsewhere.\n",
        "\n",
        "- Data extraction helps recognize which information is most valuable for accomplishing your **business objectives**, driving the overall **ETL process**.\n",
        "\n",
        "- Data is typically **analyzed** and then **crawled** through to get any **relevant** information from the **sources**.\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/e2e/data_extraction_2x_1_.png\"width=\"520\" height=\"220\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e2OLT8Z_kT5"
      },
      "source": [
        "<a name = Section11></a>\n",
        "### **1.2 Various Data Extraction Techniques?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC_o-JGEvA6s"
      },
      "source": [
        "#### **Web Data Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIMc61aO_tI4"
      },
      "source": [
        "- Web **data extraction** also known as **web scraping** is a technique for extracting **vast amounts** of data from **websites** on the internet.\n",
        "\n",
        "- The data available on **websites** is not available to **download** easily and but can be **accessed** by using a **web browser**.\n",
        "\n",
        "- Web data is of great use for **e-commerce companies**, entertainment industry, research firms, **data scientists**, **government**, social media companies and can even help the **healthcare** industry with ongoing **research** and making predictions on the **spread of diseases**.\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/e2e/shufrans-DITA-unstructured-data-1024x539.jpg\"width=\"600\" height=\"330\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6AG5Zq7v4WY"
      },
      "source": [
        "#### **API Based Data Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_00CHwWwvz6u"
      },
      "source": [
        "- An API (**Application Programming Interface**) is a **standardized** and **secure interface** that allows applications to **communicate** and work with each other.\n",
        "\n",
        "- It provides a **consistent** and standard **platform** for communication between different systems, so you do not have to create an **integration layer** yourself.\n",
        "\n",
        "-  It allows you to **automate** the **retrieval** process without needing to fetch the **data** each time.\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/e2e/602bac42d4b43d46f8ab9b94128e0463a193b649.png\"width=\"570\" height=\"280\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMuIu9gBxw5T"
      },
      "source": [
        "#### **Data Retrival From Database**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEG0hZg0v3QI"
      },
      "source": [
        "- **Database extraction** is a process of retrieving data from disparate databases.\n",
        "\n",
        "- To **retrieve** the desired data the **user present** a set of **criteria** by a query.\n",
        "\n",
        "- Then the **DBMS** provideS the **demanded** data from the database.\n",
        "\n",
        "- The **retrieved** data may be stored in a **file**, **printed**, or viewed on the screen.\n",
        "\n",
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/e2e/list-of-popular-databases-scaled.jpg\"width=\"550\" height=\"320\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHgMZonBC_1M"
      },
      "source": [
        "<a name = Section11></a>\n",
        "### **1.3 Google Storage Service**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdrYMyMIJMZ-"
      },
      "source": [
        "<br>  \n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/e2e/StorageDatabaseServices_Diagram-02.png\"width=\"600\" height=\"330\"/></center>\n",
        "\n",
        "<br>  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "<a id=section1></a>\n",
        "# **2. Introduction to BigQuery**\n",
        "---"
      ],
      "metadata": {
        "id": "ToRCI0r9YNfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<br>  \n",
        "<center><img src = \"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/image/bi14.png\" /></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "- Google BigQuery is a **serverless, highly scalable data warehouse** that comes with a built-in query engine.\n",
        "\n",
        "- The query engine is capable of **running SQL queries** on terabytes of data in a matter of seconds, and petabytes in **only minutes**. You get this **performance** without having to manage any **infrastructure** and without having to **create or rebuild indexes**.\n",
        "\n",
        "- BigQuery is considered an example of **infrastructure as a service** (IaaS). This tool can be used with **Apache Hadoop or other frameworks** to handle large data sets.\n",
        "\n",
        "- BigQuery also provides a **REST API**, which uses the Representational State Transfer (REST) model for open and **transparent collaboration**."
      ],
      "metadata": {
        "id": "OhRjh0dACXmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It's serverless, or more precisely **data warehouse as a service**. There are no servers to manage or **database software** to install.\n",
        "\n",
        "- It manages **underlying software** as well as infrastructure including **scalability and high-availability**.\n"
      ],
      "metadata": {
        "id": "OaPv0w0td_FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<br>  \n",
        "<center><img src = \"https://www.datametica.com/wp-content/uploads/2021/02/Google-BigQuery-Optimization-BLOG.png\"width=\"550\" height=\"330\" /></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "- The use cases most **suited** for BigQuery are the ones where **humans** need to perform interactive **ad-hoc queries** of read-only datasets.\n",
        "\n",
        "- Typically, BigQuery is used at the end of the **Big Data ETL pipeline** on top of processed data or in **scenarios** where complex **analytical queries** to a **relational database** take several seconds.\n",
        "\n",
        "- Because it has a **built-in cache**, BigQuery works really well in cases where the **data** does not change often.\n",
        "\n",
        "- In addition, cases where datasets are **fairly small** don’t really benefit from BigQuery, with a simple **query taking** up to a few seconds. BigQuery is really meant and suited for **BIG data and analytics**.\n",
        "\n",
        "- As a fully managed service, it works out of the box without the need to install, configure and **operate any infrastructure**.\n",
        "\n",
        "- Customers are simply **charged based** on the queries they make, and the volume of data stored.\n"
      ],
      "metadata": {
        "id": "ccuBEFOKfL09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "<a id=section1></a>\n",
        "# **3. Exploring BigQuery**\n",
        "---"
      ],
      "metadata": {
        "id": "CM4sNl4GgGG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now that we're clear with the BigQuery Objectives, let's explore and get querying!!\n",
        "\n",
        "- For this we will be using **BigQuery Sandbox** which is a free space to experiment and practice querying before you are ready to implement it in your application.\n",
        "\n",
        "- The BigQuery sandbox **lets you explore limited BigQuery capabilities at no cost to confirm whether BigQuery fits your needs**. The BigQuery sandbox lets you experience BigQuery **without providing a credit card or creating a billing account for your project.** If you already created a billing account, you can still use BigQuery at no cost in the free usage tier.\n",
        "\n",
        "- The only pre-requisite is having a google account.\n",
        "\n",
        "- Navigate to BigQuery by simply pasting this URL in your search engine:\n",
        "https://console.cloud.google.com/bigquery\n",
        "\n"
      ],
      "metadata": {
        "id": "rxyIc1MJHiTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1 Create a New Project**\n",
        "\n",
        "- Create a new project after reaching the page as we will be working in that.\n",
        "\n",
        "- Simply click on the **New Project** option and follow the prompt.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1mFjmJ91IQ19osZrZ9dCVLDQR0rX_DZzC\"/></center>\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1WpbhbxMHf7Tw4de6_CKypeC4reHSVIEW\"/></center>\n",
        "\n",
        "- If you're using a **free account** and **haven't added your credit card**, you will be **directly** taken to the sandbox, after you create a new project.\n",
        "\n",
        "- If you **already have an account where billing is enabled**, you can simply **disable the billing** of the project you're considering by going in the Billing option on the console.\n",
        "\n",
        "- Then open BigQuery and you'll be able to access the Sandbox and you won't be billed for your activities.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=19JfHePAIaV_x60jeYiVe2N0S_C2pHXjl\"/></center>"
      ],
      "metadata": {
        "id": "sRyKzJyAHh9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2 Exporting Datasets**\n",
        "\n",
        "- After you're in the sandbox, an **update option** with a sandbox prompt will be the **confirmation of your successful use of sandbox** environment activation.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1KhgiAi-pgtiPV2Cp9saDLuccZ3nMtNd8\"/></center>\n",
        "\n",
        "- The next step is uploading the **dataset for exploration**. There are a lot of ways and options to export data into BigQuery, you can explore around to see what options work the best for you.\n",
        "\n",
        "- We will be using the **Public Datasets available for free** on the cloud and will practice querying there.\n",
        "\n",
        "- Simply click on the **Open this Query** Tab and a public dataset will be opened on the left explorer bar. You can star that for later use.\n",
        "\n",
        "- We will be using the **Natality** table present in the **samples** dataset.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1TWjj_nBOO0QmzGpJDObYXPOh2kktVco7\"/></center>"
      ],
      "metadata": {
        "id": "0uD1bPOJHh4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3 Understanding the data**\n",
        "\n",
        "- BigQuery gives **several options** to explore the data.\n",
        "\n",
        "- **Schema** explains the type, descriptions and basic information of the different columns.\n",
        "\n",
        "- **Details**, as the name suggests will provide the detailed information of the data, from ids to storage details etc. For example this Natality table has around 137 million rows, indicating how good the cloud services are in dealing with Big Data.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1ukQuGESaebb76Tqa627sWpikpXUbj-UL\"/></center>\n",
        "\n",
        "- **Preview** shows the entire dataset and the values in it\n",
        "\n",
        "- **Lineage** lets you track how data moves through your systems: where it comes from, where it is passed to, and what transformations are applied to it.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1Fl7VRy87cgRn-gcYgd8zAiFkWezm74i0\"/></center>"
      ],
      "metadata": {
        "id": "Yn-j4-KbHhyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4 Querying the data**\n",
        "\n",
        "- As already discussed, the best part bigquery is that we can **perform operations on the data with the help of SQL query skills** without widening the skill gap.\n",
        "\n",
        "- After the data exploration, we can **query the data** according to the problem at hand. The **best part about cloud services is that we can query the data and pay for only the services we are using**. It helps us create a more **optimized systems** and **work on Petabytes of data without shortcomings**.\n",
        "\n",
        "- For querying the table, click on the query option and then you can start querying.\n",
        "\n",
        "- Before we start querying we will **disable using cached results**. The Use cached results option **reuses results from a previous run of the same query** unless the tables being queried have changed. **Using cached results is only beneficial for repeated queries**.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1PEweEKyBc12sR2wQ64GgiOFHnBQhoQRL\"/></center>\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1QhftCJSZb8jjREYBpctiU1A16AxqYGSP\"/></center>\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1mKqCP50mG3_7Wmg7qa0REZxfmaxWs7vz\"/></center>"
      ],
      "metadata": {
        "id": "AXeOc-p8qA22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can start querying the data now.\n",
        "\n",
        "- Let's start with a very simple query:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "SELECT * FROM `bigquery-public-data.samples.natality` LIMIT 1000\n",
        "```\n",
        "- On the top right corner, you can see the **running status of query**. Even though it's Big Data, the query results takes seconds to happen, showcasing the impact of BigQuery.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1ybISk3f6f_daA-yndpvt7zjT-hlkvV2k\"/></center>\n",
        "\n",
        "- The **Execution Details** shows all the information about running the query, like the elapsed time, how many bytes and slot time is consumed etc.\n",
        "\n",
        "- As the query gets specific, the elapsed time decreases as well.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1nNO5mgye0ublwwtBs9_DTXfHgN7w4Htr\"/></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "q1fn2LfeqA0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lets try another query:\n",
        "\n",
        "- Using natality data after the year **2000 and before 2005** and getting pluarity of born babies.\n",
        "\n",
        "- **Use the query**:\n",
        "\n",
        "\n",
        "      SELECT\n",
        "        plurality,\n",
        "        COUNT(1) AS num_babies,\n",
        "        AVG(weight_pounds) AS avg_wt\n",
        "      FROM\n",
        "        publicdata.samples.natality\n",
        "      WHERE\n",
        "        year > 2000 AND year < 2005\n",
        "      GROUP BY\n",
        "        plurality\n",
        "\n",
        "\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1-EweJST6j2pQm6rwtOTumZR_RDg568Mu\"/></center>"
      ],
      "metadata": {
        "id": "D8sZ-YB8qAx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Try getting the **no of babies born** on each day of week by yourself!\n",
        "\n",
        "- Use the **query as**:\n",
        "\n",
        "\n",
        "        SELECT\n",
        "          wday, SUM(record_weight) c\n",
        "        FROM\n",
        "          publicdata.samples.natality\n",
        "        GROUP BY wday\n",
        "        HAVING wday > 0\n",
        "        ORDER BY wday\n",
        "\n",
        "- You will be able to see several columns that seem to be **suitable for creating features** to predict the **weight** of a new born, namely: **is_male**, **plurality**,(one baby, twins, ...etc), **mother_age**, **gestation_weeks**(duration of pregnancy in weeks), **weight_gain_pounds** (weight gained by the mother during the pregnancy in pounds)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LLdCEVDSqAva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can **save the results of the query** in different formats for future uses.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=16G1XOqD814HVB_E-6XwcTFOpa4rph7ih\"/></center>"
      ],
      "metadata": {
        "id": "3DBA-8Iw1EaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.5 Data Exploration**\n",
        "\n",
        "- We can explore the queried data very easily through the **Explore Data** options, which gives different ways of performing it.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1eHkq_ywY2vbUHI2ChNIOHAC6ZeiPc5Aj\"/></center>\n",
        "\n",
        "- **Looker Studio** uses the BigQuery connector to **connect to a BI Engine-managed BigQuery table**. When you define your data source connection in Looker Studio, BI Engine uses the table and columns you configure to determine what data to cache.\n",
        "\n",
        "- **BI Engine only caches the columns you add to your report**. You can explore and customise different options and save the report for sharing and other future use.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1ZnE3eE0ZjyxflCwx1POx6DrFw4txvV_I\"/></center>\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=1nLeJAwVC0wy0o9vGJ1xtOUW28gl3FAgL\"/></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C6rBC0KPqAtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Apart from Looker Studio we can simply go for the **Python Notebook** and perform EDA on the data using queries and Python, like we have already done in the past.\n",
        "\n",
        "- When you click on the Explore with Python Notebook option, you will be redirected to a new Google Colab Notebook and all you have to do is follow the prompts and run the connection cells.\n",
        "\n",
        "- After your notebook is connected to the bigquery data, we can perform EDA and get into different graphs and data exploration.\n",
        "\n",
        "<center><img src = \"https://drive.google.com/uc?export=download&id=10FWh216MEHfi8M9yJEORNQ0501XA3I5j\"/></center>"
      ],
      "metadata": {
        "id": "jfC9HJ6twunQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "<a id=section4></a>\n",
        "# **4. Conclusion**\n",
        "---"
      ],
      "metadata": {
        "id": "SfoRyq-21a2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- All the querying and exploration that we did was totally free and done in a sandbox environment.\n",
        "\n",
        "- If you want to use your own data and be specific with the functions that you perform, **like building your own custom functions** , and exploring data and using it according to the **problem** at hand, you can always enable the billing and perform all your necessary tasks.\n",
        "\n",
        "- For custom problems, it would be advisable to use **Vertex AI Workbench** and the notebook provided there as it would offer more functionality for coding and using machine learning and deep learning to create models based on your big data.\n",
        "\n",
        "- Ofcourse whatever services that you are using, it will be on pay as you go basis, for more details, check the documentation [here](https://cloud.google.com/bigquery/docs/visualize-jupyter).\n"
      ],
      "metadata": {
        "id": "2U-mE80Q1qLj"
      }
    }
  ]
}